````markdown
---
name: ai-architect
description: >
  MANDATORY architecture analysis skill for ALL new services. Evaluates use-cases,
  asks clarifying questions, and determines optimal data platform allocation before
  ANY code generation. Produces ARCHITECTURE.md with data flow diagrams and platform
  decisions. MUST run BEFORE scaffolding code. Use when user says "create service",
  "implement system", "build application", or provides system requirements.
---

# AI Architect Skill

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                        âš ï¸  MANDATORY ARCHITECTURE PHASE  âš ï¸                               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                                          â•‘
â•‘   STOP! Before writing ANY code, you MUST:                                               â•‘
â•‘                                                                                          â•‘
â•‘   1. UNDERSTAND the use-case (ask clarifying questions)                                  â•‘
â•‘   2. DECIDE which data goes in which platform                                            â•‘
â•‘   3. DOCUMENT the architecture in ARCHITECTURE.md                                        â•‘
â•‘   4. GET USER CONFIRMATION before proceeding to code                                     â•‘
â•‘                                                                                          â•‘
â•‘   âŒ DO NOT generate code until architecture is approved!                                â•‘
â•‘   âŒ DO NOT assume data platforms - ASK if unclear!                                      â•‘
â•‘                                                                                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## Phase 0: Architecture Analysis (BEFORE Code Generation)

### Step 1: Gather Requirements

When a user provides system requirements, ASK these questions if not already answered:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                     ARCHITECTURE DISCOVERY QUESTIONS                                     â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                                          â•‘
â•‘   DATA CHARACTERISTICS:                                                                  â•‘
â•‘   â–¡ What entities need ACID transactions? (â†’ SQL Server)                                 â•‘
â•‘   â–¡ What data has complex relationships/foreign keys? (â†’ SQL Server)                     â•‘
â•‘   â–¡ What data is hierarchical/nested/flexible schema? (â†’ MongoDB)                        â•‘
â•‘   â–¡ What data is time-series (sensor readings, metrics)? (â†’ ScyllaDB)                    â•‘
â•‘   â–¡ What events need to be immutably logged? (â†’ ScyllaDB)                                â•‘
â•‘   â–¡ What data needs sub-millisecond access? (â†’ Redis)                                    â•‘
â•‘   â–¡ What events need to be streamed to multiple consumers? (â†’ Kafka)                     â•‘
â•‘                                                                                          â•‘
â•‘   SCALE & PERFORMANCE:                                                                   â•‘
â•‘   â–¡ Expected read/write ratio?                                                           â•‘
â•‘   â–¡ Expected data volume per day?                                                        â•‘
â•‘   â–¡ Latency requirements (P99)?                                                          â•‘
â•‘   â–¡ Data retention requirements?                                                         â•‘
â•‘                                                                                          â•‘
â•‘   INTEGRATION:                                                                           â•‘
â•‘   â–¡ What external systems need to be notified of changes?                                â•‘
â•‘   â–¡ Are there downstream consumers that need real-time events?                           â•‘
â•‘   â–¡ Is there a need for event sourcing/audit trail?                                      â•‘
â•‘                                                                                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Step 2: Apply Data Platform Decision Matrix

Use this matrix to decide WHERE each data type belongs:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                              DATA PLATFORM DECISION MATRIX                                            â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                                                       â•‘
â•‘   DATA TYPE                        â”‚ PRIMARY PLATFORM  â”‚ SECONDARY (Cache)  â”‚ EVENT STREAM           â•‘
â•‘   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•‘
â•‘   User accounts, roles, auth       â”‚ SQL Server        â”‚ Redis (sessions)   â”‚ Kafka (user.events)    â•‘
â•‘   Orders, transactions             â”‚ SQL Server        â”‚ Redis (hot orders) â”‚ Kafka (order.events)   â•‘
â•‘   Products, inventory              â”‚ SQL Server        â”‚ Redis (catalog)    â”‚ Kafka (inventory.*)    â•‘
â•‘   Customers, contacts              â”‚ SQL Server        â”‚ Redis (lookup)     â”‚ Kafka (customer.*)     â•‘
â•‘   Payments, invoices               â”‚ SQL Server        â”‚ -                  â”‚ Kafka (payment.*)      â•‘
â•‘   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•‘
â•‘   Device profiles, configs         â”‚ MongoDB           â”‚ Redis (active)     â”‚ Kafka (device.config)  â•‘
â•‘   User preferences, settings       â”‚ MongoDB           â”‚ Redis (session)    â”‚ -                      â•‘
â•‘   Content, documents, files meta   â”‚ MongoDB           â”‚ Redis (hot docs)   â”‚ -                      â•‘
â•‘   Automation rules, workflows      â”‚ MongoDB           â”‚ -                  â”‚ Kafka (rule.*)         â•‘
â•‘   Feature flags, A/B configs       â”‚ MongoDB           â”‚ Redis (flags)      â”‚ -                      â•‘
â•‘   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•‘
â•‘   Sensor telemetry, metrics        â”‚ ScyllaDB          â”‚ Redis (latest)     â”‚ Kafka (telemetry.*)    â•‘
â•‘   Time-series events               â”‚ ScyllaDB          â”‚ -                  â”‚ Kafka (events.*)       â•‘
â•‘   Audit logs, compliance           â”‚ ScyllaDB          â”‚ -                  â”‚ Kafka (audit.*)        â•‘
â•‘   IoT device readings              â”‚ ScyllaDB          â”‚ Redis (latest)     â”‚ Kafka (iot.*)          â•‘
â•‘   Analytics aggregates             â”‚ ScyllaDB          â”‚ Redis (dashboard)  â”‚ -                      â•‘
â•‘   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•‘
â•‘   Session state                    â”‚ Redis             â”‚ -                  â”‚ -                      â•‘
â•‘   Rate limiting                    â”‚ Redis             â”‚ -                  â”‚ -                      â•‘
â•‘   Real-time counters               â”‚ Redis             â”‚ -                  â”‚ -                      â•‘
â•‘   Pub/Sub notifications            â”‚ Redis             â”‚ -                  â”‚ -                      â•‘
â•‘   Distributed locks                â”‚ Redis             â”‚ -                  â”‚ -                      â•‘
â•‘                                                                                                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Step 3: Define Kafka Topics

For each entity/event that needs streaming, define topics:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                              KAFKA TOPIC NAMING CONVENTION                               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                                          â•‘
â•‘   Pattern: {service-name}.{entity}.{action}                                              â•‘
â•‘                                                                                          â•‘
â•‘   DOMAIN EVENTS (State Changes):                                                         â•‘
â•‘   â”œâ”€â”€ {service}.{entity}.created      # New entity created                               â•‘
â•‘   â”œâ”€â”€ {service}.{entity}.updated      # Entity modified                                  â•‘
â•‘   â”œâ”€â”€ {service}.{entity}.deleted      # Entity removed                                   â•‘
â•‘   â””â”€â”€ {service}.{entity}.{custom}     # Domain-specific events                           â•‘
â•‘                                                                                          â•‘
â•‘   COMMANDS (CQRS Pattern):                                                               â•‘
â•‘   â””â”€â”€ {service}.commands.{action}     # Request to perform action                        â•‘
â•‘                                                                                          â•‘
â•‘   NOTIFICATIONS:                                                                         â•‘
â•‘   â”œâ”€â”€ {service}.notifications.email   # Email notifications                              â•‘
â•‘   â”œâ”€â”€ {service}.notifications.push    # Push notifications                               â•‘
â•‘   â””â”€â”€ {service}.notifications.webhook # Webhook callbacks                                â•‘
â•‘                                                                                          â•‘
â•‘   INFRASTRUCTURE:                                                                        â•‘
â•‘   â””â”€â”€ {service}.dlq                   # Dead Letter Queue                                â•‘
â•‘                                                                                          â•‘
â•‘   Examples:                                                                              â•‘
â•‘   â€¢ order-service.orders.created                                                         â•‘
â•‘   â€¢ order-service.orders.status-changed                                                  â•‘
â•‘   â€¢ order-service.payments.completed                                                     â•‘
â•‘   â€¢ device-service.telemetry.readings                                                    â•‘
â•‘   â€¢ user-service.users.registered                                                        â•‘
â•‘                                                                                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Step 4: Generate ARCHITECTURE.md

BEFORE generating any code, create this document:

```markdown
# {Service Name} - Architecture Document

## Overview

{Brief description of the service and its purpose}

## Data Platform Allocation

### SQL Server (Azure SQL MI)
**Purpose:** Transactional data with ACID requirements

| Entity | Table | Relationships | Indexes |
|--------|-------|---------------|---------|
| {Entity1} | {table_name} | FK to {other} | IX_{field} |
| {Entity2} | {table_name} | FK to {other} | IX_{field} |

**Rationale:** {Why SQL Server for this data}

### MongoDB
**Purpose:** Document/hierarchical data with flexible schema

| Collection | Document Type | Indexes |
|------------|---------------|---------|
| {collection} | {type} | {indexes} |

**Rationale:** {Why MongoDB for this data}

### ScyllaDB
**Purpose:** Time-series data, event store, high-throughput writes

| Table | Partition Key | Clustering Key | TTL |
|-------|---------------|----------------|-----|
| {table} | {partition} | {clustering} | {days} |

**Rationale:** {Why ScyllaDB for this data}

### Redis
**Purpose:** Caching, sessions, real-time data

| Key Pattern | Data Structure | TTL | Purpose |
|-------------|----------------|-----|---------|
| {pattern} | {type} | {ttl} | {purpose} |

**Rationale:** {Why Redis for this data}

### Kafka Topics
**Purpose:** Event streaming, async communication

| Topic | Partitions | Retention | Consumers |
|-------|------------|-----------|-----------|
| {topic} | {n} | {hours} | {services} |

**Rationale:** {Why these events need streaming}

## Data Flow Diagram

```
[Client] â†’ [API Gateway] â†’ [Service]
                              â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â–¼               â–¼               â–¼
         [SQL Server]    [MongoDB]       [Redis Cache]
              â”‚               â”‚               â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
                          [Kafka]
                              â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â–¼               â–¼               â–¼
         [Consumer1]    [Consumer2]     [ScyllaDB]
```

## Entity Relationship

{ERD or entity descriptions}

## API Endpoints

| Method | Endpoint | Description | Data Source |
|--------|----------|-------------|-------------|
| GET | /api/v1/{entities} | List all | SQL Server + Redis |
| POST | /api/v1/{entities} | Create | SQL Server â†’ Kafka |
| GET | /api/v1/{entities}/{id} | Get one | Redis â†’ SQL Server |
| PUT | /api/v1/{entities}/{id} | Update | SQL Server â†’ Kafka |
| DELETE | /api/v1/{entities}/{id} | Delete | SQL Server â†’ Kafka |

## Event Contracts

### {service}.{entity}.created
```json
{
  "eventId": "uuid",
  "eventType": "{entity}.created",
  "timestamp": "ISO8601",
  "data": {
    "id": "uuid",
    // entity fields
  },
  "metadata": {
    "correlationId": "uuid",
    "userId": "uuid"
  }
}
```

## Caching Strategy

| Data | Cache Key | TTL | Invalidation |
|------|-----------|-----|--------------|
| {data} | {pattern} | {ttl} | {strategy} |

## Estimated Scale

| Metric | Expected Value |
|--------|----------------|
| Requests/second | {n} |
| Data volume/day | {size} |
| Active users | {n} |
| Retention period | {days} |

---

**Architecture Approved:** [ ] Yes / [ ] No
**Date:** {date}
**Architect:** Copilot + User
```

---

## Platform Selection Guidelines

### When to Use SQL Server (Azure SQL MI)

```
âœ… USE SQL SERVER WHEN:
â”œâ”€â”€ Data requires ACID transactions
â”œâ”€â”€ Complex relationships with foreign keys
â”œâ”€â”€ Need for complex JOINs across tables
â”œâ”€â”€ Referential integrity is critical
â”œâ”€â”€ Financial/payment data
â”œâ”€â”€ User accounts and authentication
â”œâ”€â”€ Order management with line items
â”œâ”€â”€ Inventory with stock transactions
â””â”€â”€ Reporting with complex aggregations

âŒ AVOID SQL SERVER WHEN:
â”œâ”€â”€ Schema changes frequently
â”œâ”€â”€ Data is deeply nested/hierarchical
â”œâ”€â”€ Write volume exceeds 10K/sec
â”œâ”€â”€ No relationships between records
â””â”€â”€ Time-series data with TTL needs
```

### When to Use MongoDB

```
âœ… USE MONGODB WHEN:
â”œâ”€â”€ Flexible/evolving schema needed
â”œâ”€â”€ Data is hierarchical/nested
â”œâ”€â”€ Document-oriented data (JSON)
â”œâ”€â”€ Device profiles with varying attributes
â”œâ”€â”€ User preferences and settings
â”œâ”€â”€ Content management (articles, posts)
â”œâ”€â”€ Configuration and feature flags
â”œâ”€â”€ Catalog data with attributes
â””â”€â”€ Workflow/rule definitions

âŒ AVOID MONGODB WHEN:
â”œâ”€â”€ Need ACID transactions across documents
â”œâ”€â”€ Heavy JOIN operations required
â”œâ”€â”€ Data is purely relational
â”œâ”€â”€ Financial ledger requiring consistency
â””â”€â”€ Simple key-value lookups (use Redis)
```

### When to Use ScyllaDB

```
âœ… USE SCYLLADB WHEN:
â”œâ”€â”€ Time-series data (sensor readings)
â”œâ”€â”€ High-throughput writes (>10K/sec)
â”œâ”€â”€ Event sourcing / audit logs
â”œâ”€â”€ IoT telemetry data
â”œâ”€â”€ Analytics aggregates
â”œâ”€â”€ Log data with TTL
â”œâ”€â”€ Immutable event store
â”œâ”€â”€ Wide-column data model fits
â””â”€â”€ Need horizontal scaling

âŒ AVOID SCYLLADB WHEN:
â”œâ”€â”€ Need complex transactions
â”œâ”€â”€ Frequent schema changes
â”œâ”€â”€ Ad-hoc queries on any column
â”œâ”€â”€ Small dataset (<1M rows)
â””â”€â”€ Need for JOINs
```

### When to Use Redis

```
âœ… USE REDIS WHEN:
â”œâ”€â”€ Sub-millisecond latency required
â”œâ”€â”€ Session state management
â”œâ”€â”€ Caching frequently accessed data
â”œâ”€â”€ Rate limiting / throttling
â”œâ”€â”€ Real-time counters / leaderboards
â”œâ”€â”€ Pub/Sub for real-time notifications
â”œâ”€â”€ Distributed locks
â”œâ”€â”€ Latest values (device readings)
â””â”€â”€ Temporary data with TTL

âŒ AVOID REDIS WHEN:
â”œâ”€â”€ Data must survive restart (use DB)
â”œâ”€â”€ Complex queries needed
â”œâ”€â”€ Data relationships exist
â”œâ”€â”€ Large objects (>1MB)
â””â”€â”€ Need for transactions
```

### When to Use Kafka

```
âœ… USE KAFKA WHEN:
â”œâ”€â”€ Event-driven architecture
â”œâ”€â”€ Multiple consumers need same events
â”œâ”€â”€ Async processing required
â”œâ”€â”€ Decoupling services
â”œâ”€â”€ Event sourcing pattern
â”œâ”€â”€ High-throughput streaming
â”œâ”€â”€ Audit trail of all changes
â”œâ”€â”€ Real-time analytics pipeline
â””â”€â”€ Replay capability needed

âŒ AVOID KAFKA WHEN:
â”œâ”€â”€ Simple request-response needed
â”œâ”€â”€ Low-volume (<100 msgs/sec)
â”œâ”€â”€ No downstream consumers
â”œâ”€â”€ Synchronous processing required
â””â”€â”€ Point-to-point only (use queue)
```

---

## Example Architecture Analysis

### User Prompt:
> "Create an Order Management System with customers, products, orders, and inventory tracking"

### Architecture Decision:

```
ENTITY ANALYSIS:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

1. CUSTOMERS
   - Has relationships (orders)
   - ACID needed for account balance
   - Relatively static data
   â†’ PRIMARY: SQL Server
   â†’ CACHE: Redis (hot customer data)
   â†’ EVENTS: Kafka (customer.created, customer.updated)

2. PRODUCTS
   - Has relationships (order items, inventory)
   - Catalog with attributes
   - Moderate update frequency
   â†’ PRIMARY: SQL Server
   â†’ CACHE: Redis (product catalog)
   â†’ EVENTS: Kafka (product.created, product.updated, product.price-changed)

3. ORDERS
   - Complex relationships (customer, items, products)
   - ACID transactions critical
   - Status changes are events
   â†’ PRIMARY: SQL Server
   â†’ CACHE: Redis (recent orders, order status)
   â†’ EVENTS: Kafka (order.created, order.status-changed, order.completed)

4. ORDER ITEMS
   - Junction table (order â†” product)
   - Part of order transaction
   â†’ PRIMARY: SQL Server (same transaction as order)
   â†’ NO separate cache (loaded with order)
   â†’ NO separate events (part of order events)

5. INVENTORY
   - High-frequency updates (stock changes)
   - Needs consistency for stock levels
   - History tracking needed
   â†’ PRIMARY: SQL Server (current stock)
   â†’ CACHE: Redis (available quantity)
   â†’ EVENTS: Kafka (inventory.adjusted, inventory.low-stock)
   â†’ HISTORY: ScyllaDB (stock movement history - time-series)

6. AUDIT LOG
   - Immutable event log
   - High-volume writes
   - Time-based queries
   â†’ PRIMARY: ScyllaDB
   â†’ EVENTS: All Kafka events â†’ ScyllaDB consumer
```

### Resulting Kafka Topics:

```
order-management.customers.created
order-management.customers.updated
order-management.products.created
order-management.products.updated
order-management.products.price-changed
order-management.orders.created
order-management.orders.status-changed
order-management.orders.completed
order-management.orders.cancelled
order-management.inventory.adjusted
order-management.inventory.low-stock
order-management.notifications.email
order-management.dlq
```

---

## Confirmation Before Code Generation

After completing architecture analysis, ALWAYS ask:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                        ARCHITECTURE CONFIRMATION                                         â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                                          â•‘
â•‘   I've analyzed your requirements and propose the following architecture:                â•‘
â•‘                                                                                          â•‘
â•‘   ğŸ“Š SQL Server:                                                                         â•‘
â•‘      â€¢ {entities}                                                                        â•‘
â•‘                                                                                          â•‘
â•‘   ğŸ“ MongoDB:                                                                            â•‘
â•‘      â€¢ {collections}                                                                     â•‘
â•‘                                                                                          â•‘
â•‘   â±ï¸ ScyllaDB:                                                                           â•‘
â•‘      â€¢ {tables}                                                                          â•‘
â•‘                                                                                          â•‘
â•‘   ğŸ”´ Redis:                                                                              â•‘
â•‘      â€¢ {cache patterns}                                                                  â•‘
â•‘                                                                                          â•‘
â•‘   ğŸ“¨ Kafka Topics:                                                                       â•‘
â•‘      â€¢ {topics}                                                                          â•‘
â•‘                                                                                          â•‘
â•‘   Do you want me to:                                                                     â•‘
â•‘   1. Proceed with this architecture and generate code?                                   â•‘
â•‘   2. Modify the platform allocation?                                                     â•‘
â•‘   3. Add/remove data platforms?                                                          â•‘
â•‘                                                                                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

Only after user confirms, proceed to:
1. Generate ARCHITECTURE.md
2. Start code generation (Phase 1 of ai-development-workflow)

---

## Integration with Development Workflow

This skill runs as **Phase 0** BEFORE the 10-phase development workflow:

```
COMPLETE SERVICE GENERATION FLOW:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

PHASE 0: Architecture (THIS SKILL)
    â”œâ”€â”€ Gather requirements
    â”œâ”€â”€ Ask clarifying questions
    â”œâ”€â”€ Analyze data characteristics
    â”œâ”€â”€ Allocate data to platforms
    â”œâ”€â”€ Define Kafka topics
    â”œâ”€â”€ Generate ARCHITECTURE.md
    â””â”€â”€ Get user confirmation
           â”‚
           â–¼
PHASE 1-10: Development Workflow (ai-development-workflow)
    â”œâ”€â”€ Phase 1: Generate Code & Seed Files
    â”œâ”€â”€ Phase 2: Build Locally
    â”œâ”€â”€ Phase 3: Run Unit Tests
    â”œâ”€â”€ Phase 4: Build Docker Image
    â”œâ”€â”€ Phase 5: Start Containers
    â”œâ”€â”€ Phase 6: Seed ALL Databases
    â”œâ”€â”€ Phase 7: Test API Endpoints
    â”œâ”€â”€ Phase 8: Test Frontend
    â”œâ”€â”€ Phase 9: Create Helm Chart
    â””â”€â”€ Phase 10: Final Status
```

````
